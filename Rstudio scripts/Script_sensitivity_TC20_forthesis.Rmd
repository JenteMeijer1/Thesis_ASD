---
title: "Normative model sensitivity analysis TC30"
author: "J. Meijer"
date: "18/04/2023"
output:
  html_document:
    toc: yes
    toc_depth: '4'
    df_print: paged
    keep_md: no
  html_notebook:
    toc: yes
    toc_depth: 4
    toc_float: yes
    theme: cosmo
    number_selection: true
editor_options: 
  markdown: 
    wrap: 72
---

This script is to run analysis from the normative model when we include 20% of the TC in the test set instead of 10% and see if this changes. So this script is for the sensitivity analysis. We will load the clustering data from the other script.

Some common notes that should be considered when running this script:

-   Make sure you run the libraries. Some functions will not necessarily
    not exist but it would not work properly.



# Setup R

```{r setup-chunk, setup, include=FALSE, cache=TRUE}
knitr::opts_chunk$set(
  dev = "png",
  dpi = 300,
  cache = TRUE,
  fig.height = 15,
  fig.width = 30
)
```

### Load work space containing clustering data

We load the workspace from the Script_final_forthesis markdown. This does mean we also load all brain data. So do not use anything directly from this workspace but run everything before you take any results. In this way we don't have to run the clustering again which is the same for the sensitivity analysis. 
```{r load workspace, cache=TRUE}
load("/Volumes/methlab/Students/Jente/Scripts/Rstudio scripts/workspace_final2.RData")
```

### Install packages

Uncomment if need to install again
```{r install packages}
# install.packages("dplyr")
# install.packages("ggplot2")
# install.packages("car")
# install.packages("rgl")
# install.packages("plotly")
# install.packages("janitor")
# install.packages("data.table")
# install.packages("GGally")
# install.packages("mclust")
# install.packages("fpc")
# install.packages("igraph")
# install.packages("Hmisc")
# install.packages("knitr)
# install.packages("devtools")
# install.packages("styler")
# install.packages("ggsignif")
# install.packages("crayon")
# install.packages("caret")

library(dplyr)
library(ggplot2)
library(stats)
library(car)
library(rgl)
library(plotly)
library(janitor)
library(data.table)
library(GGally)
library(fpc)
library(igraph)
library(Hmisc)
library(stats)
library(knitr)
library(devtools)
library(styler)
library(ggsignif)
library(crayon)
library(readr)
library(clusterpval)
library(tidyverse)
library(extRemes)
library(mclust)
library(caret)

```

# Normative modelling

From this part on we use the data from the normative model. This model is run in Python. So make sure you run the model before you start this part of the code. We also make some new dataframes we use for the plotting in python. 

## Load deviation scores from the normative model
```{r Load results normative model}
Deviation_scores <- read_csv("/Volumes/methlab/Students/Jente/Scripts/python_scripts/ASD_model_sensitivity_analysisTC20/results/blr/powell/outputs/Deviation_scores.csv", col_types = cols(...1 = col_skip()))
```


Merge with clustering results so we can compare between groups.
```{r merge dev scores with pheno data}
Brain_data_results <- merge(dataforclust, Deviation_scores, by = "SUB_ID")

#Also merge with complete dataset so we can combine diagnosis
Brain_data_results_all = merge(ABIDE_pheno_clean, Deviation_scores, by="SUB_ID")

```

## Compare deviation scores 

### Subgroups

```{r comparison abs deviation score subtypes, cache=TRUE}
#Make empty dataframe
p_values_abs <- data.frame(matrix(ncol = 3, nrow = length(colnames(Brain_data_results)[14:163])))
#Change colnames
colnames(p_values_abs) <- c("ROI", "p_value", "p_value_adjusted")

#Loop through all ROIs
i <- 0
for (ROI in colnames(Brain_data_results)[14:163]) {
  
  i <- i+1 
  
  #Create dataframe for each ROI and each subtype seperately
  data_roi <- Brain_data_results[c(ROI, "classification_model")]
  data_roi[, ROI] <- abs(data_roi[, ROI])
  data_roi_1 <- filter(data_roi, data_roi$classification_model == 1)
  data_roi_2 <- filter(data_roi, data_roi$classification_model == 2)
  
  p_values_abs[i,1] = ROI
  #Calculate Pvalue
  p_values_abs[i, 2] <- wilcox.test(as.numeric(data_roi_1[, c(ROI)]), as.numeric(data_roi_2[, c(ROI)]))$p.value
}

#Adjust p values for multiple comparison
p_values_abs$p_value_adjusted <- p.adjust(p_values_abs$p_value, method = "fdr")

for (i in 1:150){
#Plot if ROI is significant, otherwise not and show message about significance.
  if (p_values_abs[i, 3] < 0.05) {
    message(green(i, "is significant. P_value is:", p_values_abs[i, 3]))

    print(
      ggplot(data_roi, aes(x = "classification_model", y = Brain_data_results[,p_values_abs$ROI[i]])) +
        geom_boxplot(aes(fill = classification_model)) +
        theme_classic() +
        labs(x = "Classification", y = paste(p_values_abs$ROI[i], "deviation score"), title = paste(p_values_abs$ROI[i], "for each Subgroup")) +
        theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
        geom_jitter(size = 0.1) +
        scale_fill_manual(
          values = c("#5b78e2", "#b30d2e", "#a82393"), name = "Subgroup", labels =
            c("Subgroup 1", "Subgroup 2")

        )
    )

  }

  }
```

### Diagnosis
```{r comparison abs deviation score diagnosis, cache=TRUE}
# make empty dataframe to store results
p_values_diag_abs <- data.frame(matrix(ncol = 3, nrow = 0))
#Change colnames
colnames(p_values_diag_abs) <- c("ROI", "p_value", "p_value_adjusted")

i <- 0
#Loop through each ROI
for (ROI in colnames(Brain_data_results_all)[16:165]) {
  
  i <- i + 1
  
  #Save data for each ROI for each cluster
  data_roi <- Brain_data_results_all[c(ROI, "DX_GROUP")]
  data_roi[, ROI] <- abs(data_roi[, ROI])
  data_roi$DX_GROUP = as.character(data_roi$DX_GROUP)
  data_roi_1 <- filter(data_roi, data_roi$DX_GROUP == 1)
  data_roi_2 <- filter(data_roi, data_roi$DX_GROUP == 2)
  
  p_values_diag_abs[i,1] = ROI
  #Calculate p-values and save
  p_values_diag_abs[i, 2] <- wilcox.test(as.numeric(data_roi_1[, c(ROI)]), as.numeric(data_roi_2[, c(ROI)]))$p.value
  
}

#Adjust p values for multiple comparison
p_values_diag_abs$p_value_adjusted <- p.adjust(p_values_diag_abs$p_value, method = "fdr")
 
for (i in 1:150){
  #Plot if ROI is significant, otherwise not and show message about significance.
  if (p_values_diag_abs[i, 3] < 0.05) {
    message(green(p_values_diag_abs$ROI[i], "is significant. P_value is:", p_values_diag_abs[i, 3]))

    print(
      ggplot(data_roi, aes(x = DX_GROUP, y = Brain_data_results_all[,p_values_diag_abs$ROI[i]])) +
        geom_boxplot(aes(fill = DX_GROUP)) +
        theme_classic() +
        labs(x = "Group", y = paste(p_values_diag_abs$ROI[i], "deviation score"), title = paste(p_values_diag_abs$ROI[i], "for TC and Autism")) +
        theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
        geom_jitter(size = 0.1) +
        scale_fill_manual(
          values = c("#5b78e2", "#b30d2e", "#a82393"), name = "Group", labels =
            c("Autism", "TC")
        )
    )
  }
}
```

## Abnormality index with extreme value statistics
Load data
```{r load Z scores long format}
Z_df <- read.csv("/Volumes/methlab/Students/Jente/Scripts/python_scripts/ASD_model_sensitivity_analysisTC20/results/Z_df.csv")

# Make column with absolute values of CT
Z_df$CTabs <- abs(Z_df$CT)
```

Extreme value statistics
```{r extreme value statistics}
# Find maximum value for the 1% maximum or minimum of each block (i.e., subject)
Z_max <- data.frame(matrix(ncol = 4, nrow = length(unique(Z_df$SUB_ID))))
colnames(Z_max) <- c("SUB_ID", "positive_max", "negative_max", "absolute_max")

i <- 0
for (sub in unique(Z_df$SUB_ID)) {
  i <- i + 1

  Z_max[i, 1] <- sub

  positive_1pct_cutoff <- quantile(Z_df$CT[Z_df$SUB_ID == sub], 0.99, na.rm = TRUE)
  negative_1pct_cutoff <- quantile(Z_df$CT[Z_df$SUB_ID == sub], 0.01, na.rm = TRUE)
  absolute_1pct_cutoff <- quantile(Z_df$CTabs[Z_df$SUB_ID == sub], 0.99, na.rm = TRUE)

  Z_sub <- Z_df$CT[Z_df$SUB_ID == sub]
  Z_sub_abs <- Z_df$CTabs[Z_df$SUB_ID == sub]

  Z_max[i, 2] <- mean(Z_sub[Z_sub > positive_1pct_cutoff])
  Z_max[i, 3] <- mean(Z_sub[Z_sub < negative_1pct_cutoff])
  Z_max[i, 4] <- mean(Z_sub_abs[Z_sub_abs > absolute_1pct_cutoff])
}
```

### Compare diagnosis

Split into TC and ASD so we can compare the abnormality index between
these groups. We want different distributions for the groups.

```{r Prepare dataframes for comparison abnormality index diagnosis, cache=TRUE}
Z_max_ASD <- filter(Z_max, Z_max$SUB_ID %in% ABIDE_pheno_clean$SUB_ID[ABIDE_pheno_clean$DX_GROUP == 1])
Z_max_TC <- filter(Z_max, Z_max$SUB_ID %in% ABIDE_pheno_clean$SUB_ID[ABIDE_pheno_clean$DX_GROUP == 2])

# also make a column which group for the plots.
Z_max_ASD$group <- "ASD"
Z_max_TC$group <- "TC"

Z_max_diagnosis_plot <- rbind(Z_max_ASD, Z_max_TC)
```

Compare these abnormality indexes with each other

```{r compare abnoramlity index between diagnosis, cache=TRUE}
# Positive
## assumptions normality:
qqnorm(Z_max_ASD$positive_max)
qqline(Z_max_ASD$positive_max, col = "red")

qqnorm(Z_max_TC$positive_max)
qqline(Z_max_TC$positive_max, col = "red")

## assumptions equal variance:
var.test(Z_max_ASD$positive_max, Z_max_TC$positive_max)

t_test_positive <- wilcox.test(Z_max_ASD$positive_max, Z_max_TC$positive_max)

# Negative
## assumptions normality:
qqnorm(Z_max_ASD$negative_max)
qqline(Z_max_ASD$negative_max, col = "red")

qqnorm(Z_max_TC$negative_max)
qqline(Z_max_TC$negative_max, col = "red")

## assumptions equal variance:
var.test(Z_max_ASD$negative_max, Z_max_TC$negative_max)

t_test_negative <- wilcox.test(Z_max_ASD$negative_max, Z_max_TC$negative_max)

# Absolute
## assumptions normality:
qqnorm(Z_max_ASD$absolute_max)
qqline(Z_max_ASD$absolute_max, col = "red")

qqnorm(Z_max_TC$absolute_max)
qqline(Z_max_TC$absolute_max, col = "red")

## assumptions equal variance:
var.test(Z_max_ASD$absolute_max, Z_max_TC$absolute_max)

t_test_absolute <- wilcox.test(Z_max_ASD$absolute_max, Z_max_TC$absolute_max)

# Multiple comparison correction
p_values_tests = c(t_test_positive$p.value, t_test_negative$p.value, t_test_absolute$p.value)
p.adjust(p_values_tests, method="fdr")
```

Visualize the differences

```{r plot abnormality score diagnosis}
ggplot(Z_max_diagnosis_plot, aes_string(x = "group", y = "positive_max")) +
  geom_boxplot(aes(fill = group)) +
  theme_classic() +
  labs(x = "Group", y = "Abnormality index positive deviations", title = "Positive abnormality index differences between TC and Autism") +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  geom_jitter(size = 0.1) +
  scale_fill_manual(
    values = c("#5b78e2", "#b30d2e", "#a82393"), name = "Group", labels =
      c("Autism", "TC")
  )

ggplot(Z_max_diagnosis_plot, aes_string(x = "group", y = "negative_max")) +
  geom_boxplot(aes(fill = group)) +
  theme_classic() +
  labs(x = "Group", y = "Abnormality index negative deviations", title = "Negative abnormality index differences between TC and Autism") +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  geom_jitter(size = 0.1) +
  scale_fill_manual(
    values = c("#5b78e2", "#b30d2e", "#a82393"), name = "Group", labels =
      c("Autism", "TC")
  )

ggplot(Z_max_diagnosis_plot, aes_string(x = "group", y = "absolute_max")) +
  geom_boxplot(aes(fill = group)) +
  theme_classic() +
  labs(x = "Group", y = "Abnormality index absolute deviations", title = "Absolute abnormality index differences between TC and Autism") +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  geom_jitter(size = 0.1) +
  scale_fill_manual(
    values = c("#5b78e2", "#b30d2e", "#a82393"), name = "Group", labels =
      c("Autism", "TC")
  )

```

### Compare subtypes

Split into ASD subtypes so we can compare the abnormality index between
these groups. We want different distributions for the groups.

```{r prepare dataframes for abnormality index subtypes}
#Split dataframes into subtypes
Z_max_clust1 <- filter(Z_max, Z_max$SUB_ID %in% dataforclust$SUB_ID[dataforclust$classification_model == 1])
Z_max_clust2 <- filter(Z_max, Z_max$SUB_ID %in% dataforclust$SUB_ID[dataforclust$classification_model == 2])

# also make a column which group for the plots.
Z_max_clust1$group <- "clust1"
Z_max_clust2$group <- "clust2"

#Bind the dataframes together
Z_max_plot <- rbind(Z_max_clust1, Z_max_clust2)
```

Compare these abnormality indexes with each other using a t.test

```{r compare abnormality index subtypes}
# Positive
## assumptions normality:
qqnorm(Z_max_clust1$positive_max)
qqline(Z_max_clust1$positive_max, col = "red")

qqnorm(Z_max_clust2$positive_max)
qqline(Z_max_clust2$positive_max, col = "red")

## assumptions equal variance:
var.test(Z_max_clust1$positive_max, Z_max_clust2$positive_max)

t_test_positive <- wilcox.test(Z_max_clust1$positive_max, Z_max_clust2$positive_max)

# Negative
## assumptions normality:
qqnorm(Z_max_clust1$negative_max)
qqline(Z_max_clust1$negative_max, col = "red")

qqnorm(Z_max_clust2$negative_max)
qqline(Z_max_clust2$negative_max, col = "red")

## assumptions equal variance:
var.test(Z_max_clust1$negative_max, Z_max_clust2$negative_max)

t_test_negative <- wilcox.test(Z_max_clust1$negative_max, Z_max_clust2$negative_max)

# Absolute
## assumptions normality:
qqnorm(Z_max_clust1$absolute_max)
qqline(Z_max_clust1$absolute_max, col = "red")

qqnorm(Z_max_clust2$absolute_max)
qqline(Z_max_clust2$absolute_max, col = "red")

## assumptions equal variance:
var.test(Z_max_clust1$absolute_max, Z_max_clust2$absolute_max)

t_test_absolute <- wilcox.test(Z_max_clust1$absolute_max, Z_max_clust2$absolute_max)

# Multiple comparison correction
p_values_tests = c(t_test_positive$p.value, t_test_negative$p.value, t_test_absolute$p.value)
p.adjust(p_values_tests, method="fdr")
```

Visualize the abornmaility index

```{r plot abnormality index subtypes}
ggplot(Z_max_plot, aes_string(x = "group", y = "positive_max")) +
  geom_boxplot(aes(fill = group)) +
  theme_classic() +
  labs(x = "Subgroup", y = "Abnormality index positive deviations", title = "Positive abnormality index for each subgroup") +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  geom_jitter(size = 0.1) +
  scale_fill_manual(
    values = c("#5b78e2", "#b30d2e", "#a82393"), name = "Subgroups", labels =
      c("Subgroup 1", "Subgroup 2")
  )

ggplot(Z_max_plot, aes_string(x = "group", y = "negative_max")) +
  geom_boxplot(aes(fill = group)) +
  theme_classic() +
  labs(x = "Subgroup", y = "Abnormality index negative deviations", title = "Negative abnormality index for each subgroup") +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  geom_jitter(size = 0.1) +
  scale_fill_manual(
    values = c("#5b78e2", "#b30d2e", "#a82393"), name = "Subgroups", labels =
      c("Subgroup 1", "Subgroup 2")
  )

ggplot(Z_max_plot, aes_string(x = "group", y = "absolute_max")) +
  geom_boxplot(aes(fill = group)) +
  theme_classic() +
  labs(x = "Subgroup", y = "Abnormality index absolute deviations", title = "Absolute abnormality index for each subgroup") +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  geom_jitter(size = 0.1) +
  scale_fill_manual(
    values = c("#5b78e2", "#b30d2e", "#a82393"), name = "Subgroups", labels =
      c("Subgroup 1", "Subgroup 2")
  )

```


## Determine significant threshold Z-values

Now we calculate the p value so we can use our chosen threshold of p<0.005.

```{r calculate p values Z-scores}
#Calculate p values for each Z-score under a normal distribution
Z_df$pvalue <- pnorm(Z_df$CTabs, lower.tail = FALSE)

```


## Test differences in count significant deviations between groups

Count the number of significant deviations for each participant and
compare this between participants.

```{r Differences in counts}
# Count the number of significant areas
counts <- data.frame(matrix(ncol = 0, nrow = length(unique(Z_df$SUB_ID))))
counts$SUB_ID <- unique(Z_df$SUB_ID)

counts <- Z_df %>%
  group_by(SUB_ID) %>%
  summarise(counts = sum(pvalue < 0.005))

# Merge back with dataframe so we have the information about the groups.
## Compare HC with ASD

counts_all <- merge(counts, ABIDE_pheno_clean, by = "SUB_ID")

# Change diagnosis to character instead of numeric
counts_all$DX_GROUP <- as.character(counts_all$DX_GROUP)

## Test assumptions
qqnorm(counts_all$counts)
qqline(counts_all$counts, col = "red")

wilcox.test(counts_all$counts[counts_all$DX_GROUP == 1], counts_all$counts[counts_all$DX_GROUP == 2])

## Visualize
ggplot(counts_all, aes_string(x = "DX_GROUP", y = "counts")) +
  geom_boxplot(aes(fill = DX_GROUP)) +
  theme_classic() +
  labs(x = "Group", y = "Count deviations", title = "Count deviations differences between TC and Autism") +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  geom_jitter(size = 0.1) +
  scale_fill_manual(values = c("#5b78e2", "#b30d2e"), name = "Group")

    ggsave(paste("/Volumes/methlab/Students/Jente/Scripts/Rstudio scripts/Plots/Statistics NM_sensitivity_analysis/", ROI,"dif_count_diagnosis.png"))


## Compare between ASD subtypes
counts_ASD <- merge(counts, dataforclust, by = "SUB_ID")

## Test assumptions
qqnorm(counts_ASD$counts)
qqline(counts_ASD$counts, col = "red")

wilcox.test(counts_ASD$counts[counts_ASD$classification_model == 1], counts_ASD$counts[counts_ASD$classification_model == 2])

## Visualize
ggplot(counts_ASD, aes_string(x = "classification_model", y = "counts")) +
  geom_boxplot(aes(fill = classification_model)) +
  theme_classic() +
  labs(x = "Subgroup", y = "Count deviations", title = "Count deviations differences between defined subgroups") +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  geom_jitter(size = 0.1) +
  scale_fill_manual(values = c("#5b78e2", "#b30d2e"), name = "Subgroups")

    ggsave(paste("/Volumes/methlab/Students/Jente/Scripts/Rstudio scripts/Plots/Statistics NM_sensitivity_analysis/", ROI,"dif_count_subtypes.png"))
    
    
    
## Compare between subtypes and TC
    
wilcox.test(counts_ASD$counts[counts_ASD$classification_model==1], counts_all$counts[counts_all$DX_GROUP==2])
wilcox.test(counts_ASD$counts[counts_ASD$classification_model==2], counts_all$counts[counts_all$DX_GROUP==2])


```

## Save data so we can plot in python

```{r save significance data}
write.table(Z_df, "/Volumes/methlab/Students/Jente/Scripts/python_scripts/ASD_model_sensitivity_analysisTC20/results/P_df.csv", append = FALSE, sep = ",", dec = ".", col.names = TRUE)

```

## Data for brain maps subtypes

We want to get brain maps for the different subtypes as well. So let's
save the data for each subgroup seperately so it's easy to handle in
python.

```{r data for statistic brain maps subtypes}
subs_1 <- dataforclust$SUB_ID[dataforclust$classification_model == 1]
subs_2 <- dataforclust$SUB_ID[dataforclust$classification_model == 2]

Z_df_1 <- filter(Z_df, Z_df$SUB_ID %in% subs_1)
Z_df_2 <- filter(Z_df, Z_df$SUB_ID %in% subs_2)

write.table(Z_df_1, "/Volumes/methlab/Students/Jente/Scripts/python_scripts/ASD_model_sensitivity_analysisTC20/results/Z_df_subtype1.csv", append = FALSE, sep = ",", dec = ".", col.names = TRUE)

write.table(Z_df_2, "/Volumes/methlab/Students/Jente/Scripts/python_scripts/ASD_model_sensitivity_analysisTC20/results/Z_df_subtype2.csv", append = FALSE, sep = ",", dec = ".", col.names = TRUE)
```


# Sensitivity analysis
## Do comparisons with TCtest (20%)

Load sub IDs that are in the TCtest set (with 10% of TC used for test)
```{r}
subids_test_TC20 <- read.csv("/Volumes/methlab/Students/Jente/Scripts/python_scripts/ASD_model_sensitivity_analysisTC20/subids_test_TC20.csv")

subids_TCtest20 = subids_test_TC20$SUB_ID
```


Deviation scores
```{r, cache=TRUE}
# make empty dataframe to store results
p_values_diag <- data.frame(matrix(ncol = 3, nrow = 0))
#Change colnames
colnames(p_values_diag) <- c("ROI", "p_value", "p_value_adjusted")
  
i <- 0
#Loop through each ROI
for (ROI in colnames(Brain_data_results_all)[16:165]) {
  
  i <- i + 1
  
  #Save data for each ROI for each group
  data_roi <- Brain_data_results_all[c(ROI, "DX_GROUP", "SUB_ID")]
  data_roi$DX_GROUP = as.character(data_roi$DX_GROUP)
  data_roi[, ROI] <- abs(data_roi[, ROI])
  data_roi_1 <- filter(data_roi, data_roi$DX_GROUP == 1)
  data_roi_2 <- filter(data_roi, data_roi$SUB_ID %in% subids_TCtest20)

  p_values_diag[i,1] = ROI
  #Calculate p-values and save
  p_values_diag[i, 2] <- wilcox.test(as.numeric(data_roi_1[, c(ROI)]), as.numeric(data_roi_2[, c(ROI)]))$p.value

}

#Adjust p values for multiple comparison
p_values_diag$p_value_adjusted <- p.adjust(p_values_diag$p_value, method = "fdr")
  
for (i in 1:150){
  #Plot if ROI is significant, otherwise not and show message about significance.
  if (p_values_diag[i, 3] < 0.05) {
    message(green(p_values_diag$ROI[i], "is significant. P_value is:", p_values_diag[i, 3]))

    print(
      ggplot(data_roi, aes_string(x = "DX_GROUP", y = Brain_data_results_all[, p_values_diag$ROI[i]])) +
        geom_boxplot(aes(fill = DX_GROUP)) +
        theme_classic() +
        labs(x = "Group", y = paste(p_values_diag$ROI[i], "deviation score"), title = paste(p_values_diag$ROI[i], "for TCtest10 and Autism")) +
        theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
        geom_jitter(size = 0.1) +
        scale_fill_manual(
          values = c("#5b78e2", "#b30d2e", "#a82393"), name = "Group", labels =
            c("Autism", "TCtest10")
        )
    )
  }
}
```


Abnormality index:
```{r}

## Abornamlity index 
Z_max_TCtest20 = filter(Z_max, Z_max$SUB_ID %in% subids_TCtest20)
Z_max_TCtest20$group <- "TC"

t_test_positive <- wilcox.test(Z_max_ASD$positive_max, Z_max_TCtest20$positive_max)
t_test_negative <- wilcox.test(Z_max_ASD$negative_max, Z_max_TCtest20$negative_max)
t_test_absolute <- wilcox.test(Z_max_ASD$absolute_max, Z_max_TCtest20$absolute_max)


#Adjust p values with FDR correction
p_values = c(t_test_positive$p.value,t_test_negative$p.value,t_test_absolute$p.value)
p.adjust(p_values, method="fdr")

```

Compare count significant 
```{r}
wilcox.test(counts_all$counts[counts_all$DX_GROUP == 1], counts_all$counts[counts_all$SUB_ID %in% subids_TCtest20])

```


